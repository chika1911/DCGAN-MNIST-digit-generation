# -*- coding: utf-8 -*-
"""DCGAN_MNIST (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15nPqUn2fysevGIIEAgblWRqwhNN616-Z
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
import os
import PIL
import time
from tqdm.notebook import tqdm
# %matplotlib inline
import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.layers as tfl
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.losses import BinaryCrossentropy

warnings.filterwarnings('ignore')

# loading the dataset
(x_train,y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')
x_test = x_test.reshape(x_test.shape[0],28,28,1).astype('float32')
x_train = (x_train-127.5)/127.5
x_test = (x_test-127.5)/127.5
y_train= y_train.T
y_test=y_test.T

# printing the dataset
for i in range(49):
    # fig = plt.figure()
    # fig.add_subplot(7,7,i+1)
    plt.subplot(7,7,i+1)
    plt.xticks([])
    plt.yticks([])
    #plt.grid(False)
    plt.imshow(x_train[i])
    # fig = plt.figure()
    # fig.add_subplot()
    #plt.savefig('/content/output images ')
    # saveImage(fig,i)
plt.show()
#plt.savefig('my_plot.png')

# checking shape of train and test
index = 800
plt.imshow(x_train[index],cmap='gray')
plt.show()
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

# creating the generator using CNN layers
num =100
#weight_init = keras.initializers.RandomNormal(mean=0.0,stddev=0.02)
channels = 1
def Generator():
  model= tf.keras.models.Sequential([
      # 1d array for random noise
      tfl.Dense(7*7*256, use_bias='False',input_shape=[num]),
      tfl.BatchNormalization(),
      tfl.LeakyReLU(),

      tfl.Reshape([7, 7, 256]),

      # upsample to 14x14
      tfl.Conv2DTranspose(128, (5,5), (1,1), padding="same"),
      tfl.BatchNormalization(),
      tfl.LeakyReLU(),

      # upsample to 28x28
      tfl.Conv2DTranspose(64, (5,5), (2,2), padding="same"),
      tfl.BatchNormalization(),
      tfl.LeakyReLU(),

      tfl.Conv2DTranspose(1, (5,5), (2,2), padding="same", activation="tanh"),
  ])
  return model

#initialising the generator
generator = Generator()
noise = tf.random.normal(shape=[1, num])
generated_image = generator(noise, training=False)
plt.imshow(generated_image[0, :, :, 0],cmap='gray')

# creating the discriminator using CNN layers
def Discriminator():
    model = keras.models.Sequential([
        tfl.Conv2D(64, (5,5), (2,2), padding="same", input_shape=[28, 28, 1]),
        tfl.LeakyReLU(0.2),
        tfl.Dropout(0.3),

        tfl.Conv2D(128, (5,5), (2,2), padding="same"),
        tfl.LeakyReLU(0.2),
        tfl.Dropout(0.3),

        tfl.Conv2D(256, (5,5), (1,1), padding="same"),
        tfl.LeakyReLU(0.2),
        tfl.Dropout(0.3),

        tfl.Flatten(),
        tfl.Dense(1, activation='sigmoid')
    ])
    return model

# initialising the discriminator
discriminator = Discriminator()
prob = discriminator(generated_image)
print(prob)

# putting the generator and discriminator together
class DCGAN(keras.Model):
  def __init__(self,generator,discriminator, num):
    super().__init__()
    self.generator = generator
    self.discriminator = discriminator
    # self.g_metric = keras.metrics(name='g_loss')
    # self.d_metric = keras.Mean(name='d_loss')
    self.g_metric = keras.metrics.Mean(name='g_loss')
    self.d_metric = keras.metrics.Mean(name='d_loss')

  def metric(self):
    # return [g_metric,d_metric]
    return [self.g_metric, self.d_metric]

  def compile(self, g_optimizer,d_optimizer,loss):
    super(DCGAN,self).compile()

# training the now formed DCGAN
class DCGAN(keras.Model):
    def __init__(self, generator, discriminator, num):
        super().__init__()
        #generator = generator
        #discriminator = discriminator
        self.generator = generator
        self.discriminator = discriminator
        self.num = num
        self.g_metric = keras.metrics.Mean(name='g_loss')
        self.d_metric = keras.metrics.Mean(name='d_loss')

    @property
    def metrics(self):
        #return [g_metric,d_metric]
        return [self.g_metric, self.d_metric]

    def compile(self, g_optimizer, d_optimizer, loss):
        super(DCGAN, self).compile()
        self.g_optimizer = g_optimizer
        self.d_optimizer = d_optimizer
        self.loss = loss

    def train_step(self, real_images):
        #batch_size = self.shape(real_images)[0]
        #batch_size = tf.shape(real_images[0])
        batch_size = tf.shape(real_images)[0]
        random_noise = tf.random.normal(shape=(batch_size, self.num))

        # training the discriminator
        with tf.GradientTape() as tape:
            pred_real = self.discriminator(real_images, training=True)
            real_labels = tf.ones((batch_size, 1))
            real_labels += 0.05*tf.random.uniform(tf.shape(real_labels))
            d_loss_real = self.loss(real_labels, pred_real)

            fake_images = self.generator(random_noise)
            pred_fake = self.discriminator(fake_images, training=True)
            fake_labels = tf.zeros((batch_size, 1))
            d_loss_fake = self.loss(fake_labels, pred_fake)

            # calculating total loss by discriminator
            d_loss = (d_loss_real+d_loss_fake)/2


        # gradient descent for discriminator
        gradients = tape.gradient(d_loss,self.discriminator.trainable_variables)
        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))


        # training the generator
        labels = tf.ones((batch_size, 1))
        with tf.GradientTape() as tape:
            fake_images = self.generator(random_noise, training=True)
            pred_fake = self.discriminator(fake_images, training=True)

            # calculating total loss by generator
            g_loss = self.loss(labels, pred_fake)

        # gradient descent for generator
        gradients = tape.gradient(g_loss, self.generator.trainable_variables)
        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))

        self.d_metric.update_state(d_loss)
        self.g_metric.update_state(g_loss)

        return {'d_loss': self.d_metric.result(), 'g_loss': self.g_metric.result()}

# compiling and running it on train dataset
class DCGANMonitor(keras.callbacks.Callback):
    def __init__(self,num_imgs=25,latent_dim=100):
        self.num_imgs = num_imgs
        self.latent_dim = latent_dim
        # create random noise for generating images
        self.noise = tf.random.normal([25, latent_dim])

    def on_epoch_end(self, epoch, logs=None):
        g_img = self.model.generator(self.noise)
        g_img = (g_img*127.5)+127.5
        #g_img.numpy()

        fig = plt.figure(figsize=(5,5))
        for i in range(self.num_imgs):
            plt.subplot(5, 5, i+1)
            #img = array_to_img(g_img[i])
            plt.imshow(g_img[i],cmap='gray')
            plt.axis('off')
            # plt.savefig('Epoch.jpg'.format(i))
            # plt.close()
        plt.savefig('epoch_{:03d}.png'.format(epoch))
        plt.show()

    def on_train_end(self, logs=None):
        self.model.generator.save('generator.h5')

# setting initial parameter values and then applying optimizers while compiling
dcgan = DCGAN(generator=generator, discriminator=discriminator, num=num)
d = 0.0001
g = 0.0003
dcgan.compile(g_optimizer=Adam(learning_rate=g, beta_1=0.5), d_optimizer=Adam(learning_rate=d, beta_1=0.5), loss=BinaryCrossentropy())
number_epochs = 50
dcgan.fit(x_train[:20000], epochs=number_epochs , callbacks=[DCGANMonitor()])